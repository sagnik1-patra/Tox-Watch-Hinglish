{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41385254-0422-45f1-86e3-ce4ddbf77471",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] No saved model found — training now.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sagni\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SAVE] Model: C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\twh_model.joblib\n",
      "[SAVE] Label map: C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\twh_label_map.json\n",
      "[OUT] Saved: C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\twh_predictions_test.csv\n",
      "[OUT] Saved: C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\twh_predictions_test.json\n",
      "[TEST] Acc: 0.4737 | Macro-F1: 0.133\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, warnings\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from joblib import dump, load\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_recall_fscore_support, classification_report\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# ------------------ USER PATHS ------------------\n",
    "TRAIN_PATH = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\archive\\Hatespeech-Hindi_Train.csv\"\n",
    "VALID_PATH = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\archive\\Hatespeech-Hindi_Valid.csv\"\n",
    "TEST_PATH  = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\archive\\Hatespeech-Hindi_Test.csv\"\n",
    "OUT_DIR    = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\"\n",
    "\n",
    "MODEL_PATH    = os.path.join(OUT_DIR, \"twh_model.joblib\")\n",
    "LABELMAP_PATH = os.path.join(OUT_DIR, \"twh_label_map.json\")\n",
    "\n",
    "# If None → evaluate on test split. Otherwise infer on this file (.txt/.csv/.json)\n",
    "INFER_SOURCE = None\n",
    "# Examples:\n",
    "# INFER_SOURCE = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\new_comments.csv\"\n",
    "# INFER_SOURCE = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\snippets.txt\"\n",
    "# INFER_SOURCE = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\batch.json\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "TEXT_CANDS = [\n",
    "    \"text\",\"tweet\",\"sentence\",\"content\",\"message\",\"post\",\"comment\",\n",
    "    \"clean_text\",\"utterance\",\"selftext\",\"title\"\n",
    "]\n",
    "LABEL_CANDS = [\n",
    "    \"label\",\"category\",\"class\",\"target\",\"task_1\",\"task_2\",\"subtask_a\",\"hs_label\",\"y\"\n",
    "]\n",
    "\n",
    "# ------------------ HELPERS ------------------\n",
    "def ensure_out():\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "def read_csv(path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    try:\n",
    "        return pd.read_csv(path)\n",
    "    except UnicodeDecodeError:\n",
    "        return pd.read_csv(path, encoding=\"latin-1\")\n",
    "\n",
    "def detect_text_and_label(df: pd.DataFrame) -> Tuple[pd.Series, pd.Series, str, str]:\n",
    "    lower = {c.lower(): c for c in df.columns}\n",
    "\n",
    "    # text detection (or title+selftext)\n",
    "    tcol = None\n",
    "    for c in TEXT_CANDS:\n",
    "        if c in lower:\n",
    "            tcol = lower[c]; break\n",
    "    if tcol is None and \"title\" in lower and \"selftext\" in lower:\n",
    "        text = (df[lower[\"title\"]].fillna(\"\").astype(str) + \" \" +\n",
    "                df[lower[\"selftext\"]].fillna(\"\").astype(str)).str.strip()\n",
    "        tcol_used = \"title+selftext\"\n",
    "    else:\n",
    "        if tcol is None:\n",
    "            obj = [c for c in df.columns if df[c].dtype == object]\n",
    "            if not obj:\n",
    "                raise ValueError(\"No obvious text column. Rename a column to 'text'.\")\n",
    "            tcol = obj[0]\n",
    "        text = df[tcol].astype(str)\n",
    "        tcol_used = tcol\n",
    "\n",
    "    text = text.fillna(\"\").str.replace(r\"\\s+\",\" \", regex=True).str.strip()\n",
    "    mask = text != \"\"\n",
    "    text = text[mask]\n",
    "    df = df.loc[text.index]\n",
    "\n",
    "    # label detection (low-cardinality fallback)\n",
    "    lcol = None\n",
    "    for c in LABEL_CANDS:\n",
    "        if c in lower:\n",
    "            lcol = lower[c]; break\n",
    "    if lcol is None:\n",
    "        for c in df.columns:\n",
    "            uniq = pd.Series(df[c].dropna().unique())\n",
    "            if uniq.size <= 50 and (df[c].dtype == object or pd.api.types.is_integer_dtype(df[c])):\n",
    "                lcol = c; break\n",
    "    if lcol is None:\n",
    "        raise ValueError(\"No label column found. Rename to 'label' or add to LABEL_CANDS.\")\n",
    "\n",
    "    labels = df[lcol].loc[text.index]\n",
    "    return text, labels, tcol_used, lcol\n",
    "\n",
    "def build_label_map(all_labels: Dict[str, pd.Series]) -> Dict[Any, int]:\n",
    "    vals = []\n",
    "    for s in all_labels.values():\n",
    "        vals.extend(list(pd.Series(s).dropna().unique()))\n",
    "    vals = list(dict.fromkeys(vals))                         # de-dup preserve order\n",
    "    vals_sorted = sorted(vals, key=lambda x: str(x).lower()) # stable\n",
    "    return {v: i for i, v in enumerate(vals_sorted)}\n",
    "\n",
    "def apply_label_map(series: pd.Series, label2id: Dict[Any, int]) -> pd.Series:\n",
    "    mapped = series.map(lambda x: label2id.get(x, None))\n",
    "    return mapped[mapped.notna()].astype(int)\n",
    "\n",
    "def build_pipeline() -> Pipeline:\n",
    "    return Pipeline(steps=[\n",
    "        (\"tfidf\", TfidfVectorizer(\n",
    "            lowercase=True,\n",
    "            ngram_range=(1,2),       # uni+bi\n",
    "            min_df=2,\n",
    "            max_features=300_000,\n",
    "            strip_accents=\"unicode\"\n",
    "        )),\n",
    "        (\"clf\", LogisticRegression(\n",
    "            solver=\"saga\",\n",
    "            penalty=\"l2\",\n",
    "            C=1.0,\n",
    "            max_iter=400,\n",
    "            n_jobs=-1,\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight=\"balanced\",\n",
    "            multi_class=\"auto\"\n",
    "        ))\n",
    "    ])\n",
    "\n",
    "def sanitize_label_for_key(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9_]+\", \"_\", s.strip()) or \"label\"\n",
    "\n",
    "# ------------------ PREDICTION I/O ------------------\n",
    "def load_texts_for_infer(path: str) -> List[str]:\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".txt\":\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return [ln.strip() for ln in f if ln.strip()]\n",
    "    if ext == \".json\":\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, dict) and \"messages\" in data:\n",
    "            msgs = data[\"messages\"]\n",
    "            return [m[\"text\"] if isinstance(m,dict) and \"text\" in m else str(m) for m in msgs]\n",
    "        if isinstance(data, list):\n",
    "            return [d[\"text\"] if isinstance(d,dict) and \"text\" in d else str(d) for d in data]\n",
    "        raise ValueError(\"Unsupported JSON schema. Use list or {'messages': [{'text': ...}, ...]}\")\n",
    "    if ext == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        lower = {c.lower(): c for c in df.columns}\n",
    "        tcol = None\n",
    "        for c in TEXT_CANDS:\n",
    "            if c in lower: tcol = lower[c]; break\n",
    "        if tcol is None:\n",
    "            if df.shape[1] == 1: tcol = df.columns[0]\n",
    "            else: raise ValueError(\"CSV must contain a text-like column (e.g., 'text').\")\n",
    "        return df[tcol].astype(str).fillna(\"\").str.strip().tolist()\n",
    "    raise ValueError(\"Supported inference files: .txt, .csv, .json\")\n",
    "\n",
    "def save_predictions_dataframe(df: pd.DataFrame, base_name: str):\n",
    "    csv_path  = os.path.join(OUT_DIR, f\"{base_name}.csv\")\n",
    "    json_path = os.path.join(OUT_DIR, f\"{base_name}.json\")\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        payload = {\n",
    "            \"created_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"items\": df.to_dict(orient=\"records\"),\n",
    "            \"summary\": {\n",
    "                \"total\": int(len(df)),\n",
    "                \"pred_counts\": df[\"pred_label\"].value_counts().to_dict()\n",
    "            }\n",
    "        }\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "    print(\"[OUT] Saved:\", csv_path)\n",
    "    print(\"[OUT] Saved:\", json_path)\n",
    "\n",
    "# ------------------ TRAIN / LOAD ------------------\n",
    "def train_and_save(TRAIN_PATH, VALID_PATH, TEST_PATH):\n",
    "    # Load splits\n",
    "    df_train = read_csv(TRAIN_PATH)\n",
    "    df_valid = read_csv(VALID_PATH)\n",
    "    df_test  = read_csv(TEST_PATH)\n",
    "\n",
    "    # Detect columns\n",
    "    t_tr, y_tr_raw, tcol_tr, lcol_tr = detect_text_and_label(df_train)\n",
    "    t_va, y_va_raw, tcol_va, lcol_va = detect_text_and_label(df_valid)\n",
    "    t_te, y_te_raw, tcol_te, lcol_te = detect_text_and_label(df_test)\n",
    "\n",
    "    # Build consistent label map across all splits\n",
    "    label2id = build_label_map({\"train\": y_tr_raw, \"valid\": y_va_raw, \"test\": y_te_raw})\n",
    "    id2label = {int(v): str(k) for k, v in label2id.items()}\n",
    "\n",
    "    # Apply mapping and align\n",
    "    y_tr = apply_label_map(y_tr_raw, label2id)\n",
    "    y_va = apply_label_map(y_va_raw, label2id)\n",
    "    y_te = apply_label_map(y_te_raw, label2id)\n",
    "\n",
    "    X_train = pd.concat([t_tr, t_va], axis=0).astype(str).values\n",
    "    y_train = pd.concat([y_tr, y_va], axis=0).values\n",
    "    X_test  = t_te.astype(str).values\n",
    "    y_test  = y_te.values\n",
    "\n",
    "    # Build & fit\n",
    "    pipe = build_pipeline()\n",
    "    pipe.fit(X_train, y_train)\n",
    "\n",
    "    # Save model + label map\n",
    "    dump(pipe, MODEL_PATH)\n",
    "    with open(LABELMAP_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"label2id\": {str(k): int(v) for k,v in label2id.items()},\n",
    "                   \"id2label\": {str(k): v for k,v in id2label.items()}},\n",
    "                  f, ensure_ascii=False, indent=2)\n",
    "    print(\"[SAVE] Model:\", MODEL_PATH)\n",
    "    print(\"[SAVE] Label map:\", LABELMAP_PATH)\n",
    "\n",
    "    # Evaluate on TEST\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    if hasattr(pipe[-1], \"predict_proba\"):\n",
    "        proba = pipe.predict_proba(X_test)\n",
    "    else:\n",
    "        proba = None\n",
    "\n",
    "    # Metrics\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    p, r, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    report = classification_report(\n",
    "        y_test, y_pred,\n",
    "        target_names=[id2label[i] for i in sorted(set(y_test) | set(y_pred))],\n",
    "        zero_division=0\n",
    "    )\n",
    "    with open(os.path.join(OUT_DIR, \"twh_classification_report.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(report)\n",
    "\n",
    "    # Save predictions on test\n",
    "    preds_df = pd.DataFrame({\n",
    "        \"text\": X_test,\n",
    "        \"y_true\": [id2label[int(i)] for i in y_test],\n",
    "        \"pred_label\": [id2label[int(i)] for i in y_pred],\n",
    "    })\n",
    "\n",
    "    # add probability columns if available\n",
    "    if proba is not None:\n",
    "        for i in range(proba.shape[1]):\n",
    "            lab = id2label[i]\n",
    "            preds_df[f\"p_{sanitize_label_for_key(lab)}\"] = proba[:, i]\n",
    "\n",
    "    save_predictions_dataframe(preds_df, base_name=\"twh_predictions_test\")\n",
    "\n",
    "    # Update / write summary\n",
    "    summary_path = os.path.join(OUT_DIR, \"twh_infer_summary.json\")\n",
    "    base = {}\n",
    "    if os.path.exists(summary_path):\n",
    "        try:\n",
    "            with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                base = json.load(f)\n",
    "        except Exception:\n",
    "            base = {}\n",
    "    base.setdefault(\"runs\", [])\n",
    "    base[\"runs\"].append({\n",
    "        \"run_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "        \"mode\": \"TEST_EVAL\",\n",
    "        \"sources\": {\"train\": TRAIN_PATH, \"valid\": VALID_PATH, \"test\": TEST_PATH},\n",
    "        \"metrics\": {\n",
    "            \"accuracy\": round(float(acc), 4),\n",
    "            \"macro_precision\": round(float(p), 4),\n",
    "            \"macro_recall\": round(float(r), 4),\n",
    "            \"macro_f1\": round(float(f1), 4)\n",
    "        }\n",
    "    })\n",
    "    with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(base, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"[TEST] Acc:\", round(acc, 4), \"| Macro-F1:\", round(f1, 4))\n",
    "    return pipe, id2label\n",
    "\n",
    "def load_model_and_labels():\n",
    "    if not (os.path.exists(MODEL_PATH) and os.path.exists(LABELMAP_PATH)):\n",
    "        return None, None\n",
    "    pipe = load(MODEL_PATH)\n",
    "    with open(LABELMAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        maps = json.load(f)\n",
    "    id2label = {int(k): v for k, v in maps.get(\"id2label\", {}).items()}\n",
    "    return pipe, id2label\n",
    "\n",
    "# ------------------ MAIN ------------------\n",
    "def main():\n",
    "    ensure_out()\n",
    "\n",
    "    # Train if model not present; else load\n",
    "    pipe, id2label = load_model_and_labels()\n",
    "    if pipe is None:\n",
    "        print(\"[INFO] No saved model found — training now.\")\n",
    "        pipe, id2label = train_and_save(TRAIN_PATH, VALID_PATH, TEST_PATH)\n",
    "    else:\n",
    "        print(\"[INFO] Loaded model and labels from disk.\")\n",
    "\n",
    "    # If INFER_SOURCE is provided, run external predictions\n",
    "    if INFER_SOURCE is not None:\n",
    "        if not os.path.exists(INFER_SOURCE):\n",
    "            raise FileNotFoundError(INFER_SOURCE)\n",
    "        texts = load_texts_for_infer(INFER_SOURCE)\n",
    "        if not texts:\n",
    "            print(\"[WARN] No texts found to predict.\")\n",
    "            return\n",
    "\n",
    "        preds = pipe.predict(texts)\n",
    "        if hasattr(pipe[-1], \"predict_proba\"):\n",
    "            proba = pipe.predict_proba(texts)\n",
    "        else:\n",
    "            proba = None\n",
    "\n",
    "        rows = {\n",
    "            \"text\": texts,\n",
    "            \"pred_label\": [id2label[int(i)] for i in preds],\n",
    "        }\n",
    "        if proba is not None:\n",
    "            for i in range(proba.shape[1]):\n",
    "                lab = id2label[i]\n",
    "                rows[f\"p_{sanitize_label_for_key(lab)}\"] = proba[:, i]\n",
    "\n",
    "        out_df = pd.DataFrame(rows)\n",
    "        save_predictions_dataframe(out_df, base_name=\"twh_predictions_external\")\n",
    "\n",
    "        # Append to run history\n",
    "        summary_path = os.path.join(OUT_DIR, \"twh_infer_summary.json\")\n",
    "        base = {}\n",
    "        if os.path.exists(summary_path):\n",
    "            try:\n",
    "                with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                    base = json.load(f)\n",
    "            except Exception:\n",
    "                base = {}\n",
    "        base.setdefault(\"runs\", [])\n",
    "        base[\"runs\"].append({\n",
    "            \"run_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"mode\": \"EXTERNAL_INFER\",\n",
    "            \"source_file\": INFER_SOURCE,\n",
    "            \"count\": int(len(out_df))\n",
    "        })\n",
    "        with open(summary_path, \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(base, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "        print(f\"[INFER] Ran predictions on: {INFER_SOURCE}\")\n",
    "        print(out_df.head(10))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec487269-f41a-4596-b3b8-8fb73d2c5257",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
