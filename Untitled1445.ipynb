{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3daf2a88-de9c-4c37-abbe-2db5539792a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using SAMPLE_TEXTS (3 items). Set INFER_SOURCE to run on a file.\n",
      "[INFO] Loaded trained model & labels.\n",
      "\n",
      "=== Predictions (first 10) ===\n",
      "[OK ] score=0.2355: Aaj ka match mast tha, sab chill!\n",
      "[OK ] score=0.4855: I hate that community, they should go back.\n",
      "  highlights: **I hate** **that community**, they should **go back**.\n",
      "[OK ] score=0.2396: Yaar calm down, arguments se kuch solve nahi hota.\n",
      "[OUT] Saved CSV: C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\twh_hate_pred.csv\n",
      "[OUT] Saved JSON: C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\twh_hate_pred.json\n"
     ]
    }
   ],
   "source": [
    "import os, re, json, warnings\n",
    "from datetime import datetime\n",
    "from typing import Any, Dict, List, Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "OUT_DIR         = r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\"\n",
    "MODEL_PATH      = os.path.join(OUT_DIR, \"twh_model.joblib\")\n",
    "LABELMAP_PATH   = os.path.join(OUT_DIR, \"twh_label_map.json\")\n",
    "INFER_SOURCE    = None  # e.g., r\"C:\\Users\\sagni\\Downloads\\Tox Watch Hinglish\\new_comments.csv\"\n",
    "\n",
    "# If INFER_SOURCE is None, these sample texts will be used:\n",
    "SAMPLE_TEXTS = [\n",
    "    \"Aaj ka match mast tha, sab chill!\",\n",
    "    \"I hate that community, they should go back.\",\n",
    "    \"Yaar calm down, arguments se kuch solve nahi hota.\"\n",
    "]\n",
    "\n",
    "# Zero-shot threshold (after heuristic boost)\n",
    "ZS_HATE_THRESHOLD = 0.50\n",
    "\n",
    "# Which class names from your label map count as hateful (case-insensitive substring match)\n",
    "HATE_NAME_HINTS = {\"hate\", \"hatespeech\", \"hs\"}  # extend if your dataset uses different wording\n",
    "\n",
    "# Column detection candidates for CSV\n",
    "TEXT_CANDS = [\n",
    "    \"text\",\"tweet\",\"sentence\",\"content\",\"message\",\"post\",\"comment\",\n",
    "    \"clean_text\",\"utterance\",\"selftext\",\"title\"\n",
    "]\n",
    "\n",
    "# ------------------- OPTIONAL: LOAD TRAINED MODEL -------------------\n",
    "from joblib import load as joblib_load\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "def load_trained_model_if_available() -> Tuple[Optional[Pipeline], Optional[Dict[int,str]]]:\n",
    "    if os.path.exists(MODEL_PATH) and os.path.exists(LABELMAP_PATH):\n",
    "        try:\n",
    "            pipe = joblib_load(MODEL_PATH)\n",
    "            with open(LABELMAP_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "                maps = json.load(f)\n",
    "            id2label = {int(k): v for k, v in maps.get(\"id2label\", {}).items()}\n",
    "            print(\"[INFO] Loaded trained model & labels.\")\n",
    "            return pipe, id2label\n",
    "        except Exception as e:\n",
    "            print(\"[WARN] Could not load model/labels; falling back to zero-shot.\", e)\n",
    "    else:\n",
    "        print(\"[INFO] No saved model found; using zero-shot fallback.\")\n",
    "    return None, None\n",
    "\n",
    "# ------------------- ZERO-SHOT FALLBACK (multilingual) -------------------\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "_zs_pipeline = None\n",
    "\n",
    "def ensure_zero_shot():\n",
    "    \"\"\"\n",
    "    Multilingual NLI zero-shot model (good for Hinglish/Indic code-mix).\n",
    "    \"\"\"\n",
    "    global _zs_pipeline\n",
    "    if _zs_pipeline is None:\n",
    "        try:\n",
    "            from transformers import pipeline\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(\n",
    "                \"Transformers not installed. Install with: pip install transformers\"\n",
    "            ) from e\n",
    "        # Multilingual XLM-RoBERTa NLI works well across languages/code-mix\n",
    "        _zs_pipeline = pipeline(\n",
    "            \"zero-shot-classification\",\n",
    "            model=\"joeddav/xlm-roberta-large-xnli\",\n",
    "            device=-1\n",
    "        )\n",
    "\n",
    "def zero_shot_hate_prob(texts: List[str]) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Return p_hateful in [0,1] for each text.\n",
    "    \"\"\"\n",
    "    ensure_zero_shot()\n",
    "    labels = [\"hateful language\", \"not hateful\"]\n",
    "    probs = []\n",
    "    for t in texts:\n",
    "        out = _zs_pipeline(t, labels, hypothesis_template=\"This text contains {label}.\")\n",
    "        p = 0.0\n",
    "        for lab, sc in zip(out[\"labels\"], out[\"scores\"]):\n",
    "            if lab == \"hateful language\":\n",
    "                p = float(sc); break\n",
    "        probs.append(p)\n",
    "    return np.array(probs, dtype=float)\n",
    "\n",
    "# ------------------- HEURISTICS + HIGHLIGHTS -------------------\n",
    "# Intentionally avoid explicit slurs in this demo. You can extend with a private lexicon.\n",
    "HATE_PATTERNS = {\n",
    "    \"violent_intent\": r\"\\b(kill|wipe\\s+(them|those)|exterminate|get rid of|eliminate)\\b\",\n",
    "    \"exclusion\": r\"\\b(go back|kick (them|those) out|throw (them|those) out|send (them|those) back)\\b\",\n",
    "    \"broad_dehumanizing\": r\"\\b(these people|that community|vermin|animals|dirty)\\b\",\n",
    "    \"explicit_hate_word\": r\"\\bI hate\\b|\\bhate (them|those|that)\\b\"\n",
    "}\n",
    "\n",
    "def highlight_spans(text: str) -> List[Tuple[int,int,str]]:\n",
    "    hits = []\n",
    "    for tag, pat in HATE_PATTERNS.items():\n",
    "        for m in re.finditer(pat, text, flags=re.I):\n",
    "            hits.append((m.start(), m.end(), tag))\n",
    "    return hits\n",
    "\n",
    "def heuristic_boost(p_hate: float, spans: List[Tuple[int,int,str]]) -> float:\n",
    "    \"\"\"\n",
    "    Boost probability based on explainable phrases; clamp to [0,1].\n",
    "    \"\"\"\n",
    "    boost = 0.0\n",
    "    tags = {t for *_ , t in spans}\n",
    "    if \"violent_intent\" in tags: boost += 0.25\n",
    "    if \"exclusion\" in tags: boost += 0.15\n",
    "    if \"broad_dehumanizing\" in tags or \"explicit_hate_word\" in tags: boost += 0.10\n",
    "    return max(0.0, min(1.0, p_hate + boost))\n",
    "\n",
    "# ------------------- FILE LOADING -------------------\n",
    "def load_texts_from_file(path: str) -> List[str]:\n",
    "    ext = os.path.splitext(path)[1].lower()\n",
    "    if ext == \".txt\":\n",
    "        with open(path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            return [ln.strip() for ln in f if ln.strip()]\n",
    "    if ext == \".json\":\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        if isinstance(data, dict) and \"messages\" in data:\n",
    "            msgs = data[\"messages\"]\n",
    "            return [m[\"text\"] if isinstance(m, dict) and \"text\" in m else str(m) for m in msgs]\n",
    "        if isinstance(data, list):\n",
    "            return [d[\"text\"] if isinstance(d, dict) and \"text\" in d else str(d) for d in data]\n",
    "        raise ValueError(\"Unsupported JSON schema. Use list or {'messages':[{'text':...}]} .\")\n",
    "    if ext == \".csv\":\n",
    "        df = pd.read_csv(path)\n",
    "        lower = {c.lower(): c for c in df.columns}\n",
    "        tcol = None\n",
    "        for c in TEXT_CANDS:\n",
    "            if c in lower: tcol = lower[c]; break\n",
    "        if tcol is None:\n",
    "            if df.shape[1] == 1: tcol = df.columns[0]\n",
    "            else: raise ValueError(\"CSV must contain a text-like column (e.g., 'text').\")\n",
    "        return df[tcol].astype(str).fillna(\"\").str.strip().tolist()\n",
    "    raise ValueError(\"Supported inputs: .txt / .csv / .json\")\n",
    "\n",
    "# ------------------- PREDICTION CORE -------------------\n",
    "def hateful_from_model(pipe: Pipeline, id2label: Dict[int,str], texts: List[str]) -> pd.DataFrame:\n",
    "    preds = pipe.predict(texts)\n",
    "    if hasattr(pipe[-1], \"predict_proba\"):\n",
    "        proba = pipe.predict_proba(texts)\n",
    "    else:\n",
    "        proba = None\n",
    "\n",
    "    # Identify which class IDs correspond to hateful labels\n",
    "    hate_ids = set()\n",
    "    for i, name in id2label.items():\n",
    "        if any(hint in name.lower() for hint in HATE_NAME_HINTS):\n",
    "            hate_ids.add(i)\n",
    "\n",
    "    rows = []\n",
    "    for idx, t in enumerate(texts):\n",
    "        spans = highlight_spans(t)\n",
    "        if proba is not None:\n",
    "            p_hate = float(np.sum(proba[idx, list(hate_ids)])) if hate_ids else 0.0\n",
    "            p_hate = heuristic_boost(p_hate, spans)\n",
    "        else:\n",
    "            # If no class probabilities, approximate from label\n",
    "            p_hate = 1.0 if int(preds[idx]) in hate_ids else 0.0\n",
    "            p_hate = heuristic_boost(p_hate, spans)\n",
    "\n",
    "        is_hate = 1 if p_hate >= 0.5 else 0\n",
    "        rows.append({\n",
    "            \"text\": t,\n",
    "            \"is_hateful\": is_hate,\n",
    "            \"hateful_score\": round(p_hate, 4),\n",
    "            \"model_label\": id2label.get(int(preds[idx]), str(int(preds[idx]))),\n",
    "            \"highlights\": spans\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def hateful_zero_shot(texts: List[str]) -> pd.DataFrame:\n",
    "    base_p = zero_shot_hate_prob(texts)\n",
    "    rows = []\n",
    "    for t, p in zip(texts, base_p):\n",
    "        spans = highlight_spans(t)\n",
    "        boosted = heuristic_boost(float(p), spans)\n",
    "        is_hate = 1 if boosted >= ZS_HATE_THRESHOLD else 0\n",
    "        rows.append({\n",
    "            \"text\": t,\n",
    "            \"is_hateful\": is_hate,\n",
    "            \"hateful_score\": round(boosted, 4),\n",
    "            \"model_label\": \"zero-shot\",\n",
    "            \"highlights\": spans\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def detect_hateful_language(texts: List[str]) -> pd.DataFrame:\n",
    "    pipe, id2label = load_trained_model_if_available()\n",
    "    if pipe is not None and id2label:\n",
    "        return hateful_from_model(pipe, id2label, texts)\n",
    "    return hateful_zero_shot(texts)\n",
    "\n",
    "# ------------------- SAVE -------------------\n",
    "def save_predictions(df: pd.DataFrame, base_name: str = \"twh_hate_pred\"):\n",
    "    os.makedirs(OUT_DIR, exist_ok=True)\n",
    "    csv_path  = os.path.join(OUT_DIR, f\"{base_name}.csv\")\n",
    "    json_path = os.path.join(OUT_DIR, f\"{base_name}.json\")\n",
    "    df.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        payload = {\n",
    "            \"created_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "            \"items\": df.to_dict(orient=\"records\"),\n",
    "            \"summary\": {\n",
    "                \"total\": int(len(df)),\n",
    "                \"hateful\": int((df[\"is_hateful\"]==1).sum()),\n",
    "                \"not_hateful\": int((df[\"is_hateful\"]==0).sum())\n",
    "            }\n",
    "        }\n",
    "        json.dump(payload, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(\"[OUT] Saved CSV:\", csv_path)\n",
    "    print(\"[OUT] Saved JSON:\", json_path)\n",
    "\n",
    "# ------------------- MAIN -------------------\n",
    "def main():\n",
    "    # Load texts\n",
    "    if INFER_SOURCE is None:\n",
    "        texts = [t for t in SAMPLE_TEXTS if t.strip()]\n",
    "        print(f\"[INFO] Using SAMPLE_TEXTS ({len(texts)} items). Set INFER_SOURCE to run on a file.\")\n",
    "    else:\n",
    "        if not os.path.exists(INFER_SOURCE):\n",
    "            raise FileNotFoundError(INFER_SOURCE)\n",
    "        texts = load_texts_from_file(INFER_SOURCE)\n",
    "        print(f\"[INFO] Loaded {len(texts)} texts from:\", INFER_SOURCE)\n",
    "\n",
    "    if not texts:\n",
    "        print(\"[WARN] No texts to analyze.\")\n",
    "        return\n",
    "\n",
    "    # Predict\n",
    "    df = detect_hateful_language(texts)\n",
    "\n",
    "    # Pretty print sample\n",
    "    print(\"\\n=== Predictions (first 10) ===\")\n",
    "    for _, r in df.head(10).iterrows():\n",
    "        print(f\"[{'HATE' if r['is_hateful']==1 else 'OK '}] score={r['hateful_score']}: {r['text'][:120]}\")\n",
    "        if r[\"highlights\"]:\n",
    "            # Make spans visible with **markers**\n",
    "            s = r[\"text\"]\n",
    "            # careful: replace in reverse order to keep indices valid\n",
    "            for (start, end, tag) in sorted(r[\"highlights\"], key=lambda x: x[0], reverse=True):\n",
    "                s = s[:start] + \"**\" + s[start:end] + \"**\" + s[end:]\n",
    "            print(\"  highlights:\", s)\n",
    "\n",
    "    # Save\n",
    "    save_predictions(df)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec0b91c-b3ef-4cc5-a88e-978d9fa18317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (moviepy)",
   "language": "python",
   "name": "py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
